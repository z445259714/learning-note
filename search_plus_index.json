{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-16 17:14:58 "},"java/00-首页.html":{"url":"java/00-首页.html","title":"JAVA","keywords":"","body":" JAVA JAVA编程语言 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-16 22:04:40 "},"java/02-jvm.html":{"url":"java/02-jvm.html","title":"JDK基本原理","keywords":"","body":" JVM原理​ jvm原理图解 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-16 22:07:23 "},"java/01-jdk1.8.html":{"url":"java/01-jdk1.8.html","title":"Jdk1.8特性","keywords":"","body":" ​JDK1.8 特性 1、速度更快 ​ 1）、对Map进行优化，数组+链表+红黑树 ​ 2）、对JVM进行优化，取消永久代，改为元空间，内存直接使用物理内存。 2、Lambda表达式 (a) -> System.out.print(a); ​ 左侧：参数列表 ​ 右侧：表达式中所要执行的功能，即 Lambda体 ​ 语法格式一：无参数无返回值 () -> System.out.print(\"aaa\"); ​ 语法格式二：有一个参数并且无返回值 (x) -> System.out.print(x); ​ 语法格式三：若只有一个参数，括号可以不写 x -> System.out.print(x); ​ 语法格式四：有两个参数，有返回值，并且 Lambda体有多条执行语句 Comperator com = (x, y) -> { System.out.print(x); return x - y; }; ​ 语法格式五：若Lambda体中只有一条语句，有返回值，return和大括号可以不写 Comperator com = (x, y) -> Integer.compare(x, y); ​ 语法格式六：Lambda表达式的参数列表的数据类型可以省略不写，因为JVM在编译的时候通过上下文推断出数据类型，即\"类型推断\" Comperator com = (Integer x, Integer y) -> Integer.compare(x, y); Comperator com = (x, y) -> Integer.compare(x, y); 总结：Lambda表达式对函数式接口类功能实现的简化。函数式接口是指接口中只有一个抽象方法，可以用注释@FunctionalInterface来限制接口类只有一个抽象方法。 @FunctionalInterface public interface Test() { public void test(T t); // 如果定义多个接口将无法编译通过 public void test1(T t); // 不允许 } 3、Java8 内置核心函数式接口 1、Consumer: 消费型接口 ​ void accept(T t); // 需求：打印接收到数据 @Test public void test1() { happy(100,(e) -> System.out.print(\"我消费了\" + e +“元”)); } public void happy(double money, Consumer con) { con.accept(money); } 2、Supplier: 供给型接口 ​ T get(); // 需求：产生指定个数的整数 @Test public void test2() { List list = getNumList(10, () -> (int)Math.random() * 100); for (Integer a : list){ System.out.println(...); } } public List getNumList(int num, Supplier sup) { List list = new ArrayList(); for (int i = 0; i 3、Function: 函数型接口 ​ R apply(T t); // 需求：对字符串进行处理 @Test public void test3() { String str = subStr(\"你是谁啊？\", (e) -> e.substring(1,3)); System.out.println(str); } public String subStr(String str, Function(String, String) fun) { retun fun.apply(str); } 4、Predicate: 断言型接口 ​ boolean test(T t); // 将满足的条件提取出来 @Test public void test4() { List list = Arrays.asList(\"hell0\",\"ok\"); List newList = filterStr(list, (e) -> e.length > 2); for (String str : newList) { System.out.println(str); } } public List filterStr(List list, Predicate pred) { List newList = new ArrayList(); for (String str : list) { // 做判断 if (pred.test(str)) { newList.add(str); } } } 4、Lambda表达式方法引用 ​ 方法引用：若Lambda 体中的内容有方法已经实现了，我们可以使用\"方法引用\" ​ （可以理解为方法引用是Lambda 表达式的另外一种表达方式） ​ 主要有三种语法方式： 1. 对象::实例方法名 2. 类::静态方法名 3. 类::实例方法吗 // 对象::实例方法名 public void test1() { Consumer con = (x) -> System.out.println(x); PrintStream ps = System.out; Consumer con = ps::println; con.accept(\"说明一下!\"); } // 类::静态方法名 public void test2() { Predicate pred = (x) -> StringUtils.isEmpty(x); Predicate pred1 = StringUtils::isEmpty; } // 类::实例方法名 public void test3() { BiPredicate pred = (x, y) -> x.equals(y); BiPredicate pred1 = String::equals; } ​ 注意： 1. Lambda 表达式使用方法引用必须保证已经实现的方法的**参数类表**和**返回值**与函数式接口的**参数列表**和**返回值**保持一致 2. 在使用**类::实例方法名**时，方法的第一个参数作为方法的调用，第二个参数作为方法的参数才可以这样使用。例：**x.equals(y)** 5、Lambda构造器引用 ​ 语法方式：类::new public void test() { Supplier sup = () -> new Employee(); // 构造器没有参数 Supplier sup = Employee::new; // 构造器一个参数 Function = Employee::new; // 构造器两个参数 BiFunction = Employee::new; } public class Employee{ private int id; private String name; private int age; public Employee() { } public Employee(String name) { this.name = name } public Employee(int id, String name) { this.id = id; this.name = name; } } ​ 注意：需要调用的构造器的参数列表需要与函数式接口中抽象方法的参数列表保持一致 ​ 数组引用 ​ 语法：类型[]:new public void test() { Function fun = (x) -> new String[x]; Function fun = String[]:new; } 6、Stream Api 1)、Stream 创建 ​ 创建方法： 可以通过Connection 系列集合提供的stream()或者parallelstream()方法创建 List list = new ArrayList(); Stream stream = list.stream(); 通过Arrays 中的静态方法stream()创建 Empoyee[] emp = new Empoyee[10]; Stream stream = Arrays.stream(emp); 3. 通过Stream类中的静态方法of()创建 Stream stream = Stream.of(\"aa\",\"bb\",\"cc\"); 4. 创建无限流 // 迭代 Stream stream = Stream.interate(0, (x) -> x+2); // 生成 Stream stream = Stream.generate(() -> Math.random()); 2)、Stream 操作 ​ 中间操作不会执行任何操作，只有调用终止操作才会一次性执行全部内容，即\"惰性操作\" 过滤与切片 filter--接收Lambda,从流中排除某些元素； limit(n)--截断，使其元素不超过给定数量；（获取到指定的数量后就不在执行，可以提高效率） skip(n)--跳过元素，返回一个扔掉了前n个元素的流，若流中元素不足n个，则返回一个空流，与limit(n)互补 distinct--筛选，通过流所生成元素的hashCode()和equals()去除重复数据，对于自定义的类需要重写haseCode()和equals()方法。 public void test() { List strList = Arrays.asList(\"aa\",\"bb\",\"dada\"); strList.stream.filter((x) -> x.length > 2) .forEach(System.out::println); } 映射 map--接收Lambda表达式，将元素转换成其他元素或提取信息。接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素 public void test() { List list = Arrays.asList(\"aa\", \"bb\", \"cc\"); list.stream() .map((x) -> x.toUpperCase()) .forEach(System.out::println); // 最后输出结果 // ['AA','BB','CC'] } flatMap--接收一个函数作为参数，将流中的每个元素值都换成另外一个流，然后把所有流连接成一个流 public void test() { List list = Arrays.asList(\"aa\", \"bb\", \"cc\"); // 嵌套了两层的Stream list.stream() .map((x) -> character(x)) .forEach((x) -> x.forEach(System.out::println)); // flatMap 会将多个流合并成一个流 list.stream() .flatMap((x) -> character(x)) .forEach(System.out::println); } // 将字符串转成字符集合 public Stream character(String str) { List list = new ArrayList(); for (Character c : str.toCharArray()) { list.add(c); } return list.stream(); } 排序 sorted--自然排序(Comparable)，如果自定义类自然排序需要实现Comparable接口，可参考String类 sorted(Comparator com)--自定义排序(Comparator) public void test() { List list = Arrays.asList(1,2,5,3,7); list.stream() .sorted() .forEach(System.out::println); // 自定义排序 list.stream() .sorted((x1, x2) -> -x1.compareTo(x2)) .forEach(System.out::println); } 3)、Stream 结束 public class Employee{ private String name; private double salary; private int state; .... } List list = Arrays.asList( new Employee(\"张三\"，5000.90, 1); new Employee(\"李四\"，4350.90, 0); new Employee(\"王五\"，3490.90, 3); ); allMatch -- 检查是否匹配所有的元素 // 检查所有都匹配 boolean b1 = list.stream() .allMatch((e) -> e.getState == 1); System.out.println(b1); anyMatch -- 检查是否至少匹配一个元素 // 检查有一个匹配 boolean b2 = list.stream() .anyMatch((e) -> e.getState == 1); System.out.println(b1); noneMatch -- 检查是否没有匹配所有元素 // 检查是否没有匹配所有元素 boolean b2 = list.stream() .anyMatch((e) -> e.getState == 1); System.out.println(b1); findFirst -- 返回第一个元素 // 查找按工资排序后第一个 Optional op = list.stream() .sort((e1, e2) -> Doublie.compare(e1.getSalary, e2.getSalary)) .findFirst(); System.out.println(op.get()); findAny -- 返回当前流中任一元素 (并行操作) Optional op = list.stream() .sort((e1, e2) -> Doublie.compare(e1.getSalary, e2.getSalary)) .findAny(); System.out.println(op.get()); count -- 返回流中元素的总量 // 计算总数 Long count = list.stream() .count(); System.out.println(count); max -- 返回流中最大值 // 获取最大值 Optional op1 = list.stream() .max((e1, e2) -> Doublie.compare(e1.getSalary, e2.getSalary)); System.out.println(op1.get()); min -- 返回流中最小值 // 获取最小 Optional op2 = list.stream() .map(Employee::getSaraly) .min(Double::compare); System.out.println(op2.get()); reduce -- 规约,可以将流中元素反复结合起来，得到一个值 reduce(T indentity, BinaryOperate); indentity：为初始值 public void test() { List list = Arrays.asList(1,2,3,4); Integer sum = list.stream() .reduce(0, (x, y) -> x +y); System.out.println(sum); // 得到的结果为 10； } 注意：map-reduce模式在互联网中使用非常的频繁 collect -- 收集，将流转换成其他形式。接收一个Collector接口的实现类，用于给stream中的元素做汇总。 1、将结果集转成其他类型的集合 public static void test() { List list = Arrays.asList(new Employee(\"张三\", 5033.33, 21), new Employee(\"李四\", 4033.33, 25), new Employee(\"王五\", 4433.33, 21), new Employee(\"赵六\", 6033.33, 30), new Employee(\"田七\", 3033.33, 19), new Employee(\"田七\", 6733.33, 39)); // 转成List List nameList = list.stream() .map(Employee::getName) .collect(Collectors.toList()); nameList.forEach(System.out::println); System.out.println(\"------------------------------------\"); // 转成Set Set set = list.stream() .map(Employee::getName) .collect(Collectors.toSet()); set.forEach(System.out::println); System.out.println(\"------------------------------------\"); // 转成指定的Collection HashSet hs = list.stream() .map(Employee::getName) .collect(Collectors.toCollection(HashSet::new)); hs.forEach(System.out::println); } 2、收集结果的值 public static void test2() { // 总数 Long count = list.stream() .collect(Collectors.counting()); System.out.println(count); System.out.println(\"------------------------------------\"); // 平均值 Double db = list.stream() .collect(Collectors.averagingDouble(Employee::getSalary)); System.out.println(db); System.out.println(\"------------------------------------\"); // 总和 Double sum = list.stream() .collect(Collectors.summingDouble(Employee::getSalary)); System.out.println(sum); System.out.println(\"------------------------------------\"); // 最大值 Optional op = list.stream() .collect(Collectors.maxBy((e1, e2) -> Double.compare(e1.getSalary(), e2.getSalary()))); System.out.println(op.get()); } 3、分组 public static void test3() { // 按姓名分组 Map> map = list.stream() .collect(Collectors.groupingBy(Employee::getName)); System.out.println(map); System.out.println(\"------------------------------------\"); // 多次分组 Map>> map1 = list.stream() .collect(Collectors.groupingBy(Employee::getName, Collectors.groupingBy((e) -> { if (((Employee) e).getAge() 4、分区（分为true或者false两个区） public static void test4() { Map> map = list.stream() .collect(Collectors.partitioningBy((e) -> e.getSalary() > 5000)); System.out.println(map); } 5、获取总和、平均值、最大最小值的另外一种方法 public static void test5() { DoubleSummaryStatistics dd = list.stream() .collect(Collectors.summarizingDouble(Employee::getSalary)); System.out.println(dd.getMax()); } 6、拼接字符串--join public static void test6() { String dd = list.stream() .map(Employee::getName) .collect(Collectors.joining(\",\")); System.out.println(dd); } 7、 Optional 容器类 1、Optional.of(T t) -- 创建一个实例 Optional op = Optional.of(new Employee()); Employee employee = op.get(); System.out.println(employee); 2、Optional.empty() -- 创建一个空实例 3、Optional.ofNullable(T t) -- 若t存在创建一个实例，如果不存在创建一个空实例 4、isPresent() -- 判断是否有值 if (op.isPresent()) { System.out.println(op.get()); } 5、orElse(T t) -- 如果容器有值返回值，否则返回t 6、orElseGet(Supplier s) -- 如果调用对象包含值，返回该值，否则返回s获取的值 op.orElseGet(() -> new Employee()); 7、map(Function f) -- 如果有值对其处理，并返回处理后的Optional,否则返回Optional.empty(); Optional op1 = op.map((e) -> e.getName()); System.out.println(op1.get()); 8、flatMap(Function f) -- 与map类似，要求返回值必须Optional 8、 接口的默认方法和静态方法 1、接口的默认方法 用default修饰 public interface MyClass{ public default String getName() { return \"张三\"; } } 注意：接口方法的\"类优先\"原则 若接口中定义一个默认方法，而另外一个父类或接口中又定义了一个同名的方法时 选择父类中的方法。如果父类提供了具体的实现，那么接口中具体相同名称和参数默认方法被忽略； 接口冲突。如果一个接口提供了默认方法，而另一个接口也提供了具有相同名称和参数的默认方法，那么必须覆盖该方法来解决冲突 public interface MyClass1{ public default String getName() { return \"李四\"; } } public class myFun implements MyClass, MyClass1 { public default String getName() { return MyClass.super.getName(); } } 2、接口中的静态方法 public interface MyClass1{ public static String getName() { return \"王五\"; } } 9、新时间和日期API 1、LocalDate(日期)、LocalTime(时间)、LocalDateTime(日期+时间) public void test() { LocalDateTime ldt = LocalDateTime.now(); System.out.println(ldt); LocalDateTime ldt2 = LocalDateTime.of(2021, 1, 24, 10,13,34); System.out.println(ldt2); // 时间计算 // 加 LocalDateTime ldt3 = ldt.plusYear(1); System.out.println(ldt3); // 减 LocalDateTime ldt3 = ldt.minusHour(1); System.out.println(ldt3); // 获取年、月、日、时 System.out.println(ldt3.getYear()); ... } 2、Instant(时间戳) public void test() { Instant ins = Instant.now();// 获取UTC时间(与我们相差8个小时) System.out.println(ins); OffsetDateTime odt = ins.atOffset(ZoneOffset.ofHours(8)); System.out.println(odt); // 获取毫秒的时间戳 System.out.println(ins.toEpochMilli()); } 3、计算时间间隔 1）、Duration：计算两个\"时间\"之间的间隔 public void test() { Instant ins = Instant.now(); try { Thread.sleep(100); }catch(Exception e){} Instant ins2 = Instant.now(); Duration drt = Duration.between(ins,ins1); // 获取毫秒差 System.out.println(drt.toMillis()); } 2)、Period：计算两个\"日期\"之间的间隔 public void test() { LocalDate ld = LocalDate.of(2020,3,24); LocalDate ld1 = LocalDate.now(); Period pd Period.between(ld, ld1); // 相差的天数 System.out.println(pd.getDay()); } 4、TemporalAdjuster时间矫正器 public void test{ LocalDateTime ldt1 = LocalDateTime.now(); // 将日期修改为10号 LocalDateTime ldt2 = LocalDateTime.withDayofMonth(10); // 计算下一个星期日 LocalDateTime ldt3 = ldt.with(TemporalAdjusters.next(DayofWeek.sunDay)); // 自定义 LocalDateTime ldt4 = ldt.with((l) -> { LocalDateTime ldt5 = (LocalDateTime)l; DayofWeek dow = ldt5.getDayofWeek(); if (dow.equals(DayofWeek.FRIDAY)) { return ldt5.plusDays(3); } }); } 10、 时间格式化 1、DateTimeFormatter : 格式化时间/日期 public void test{ DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); LocalDateTime ldt = LocalDateTime.now(); String strDate = dtf.format(ldt); // 将字符串转换回去 LocalDateTime ldt1 = ldt.parse(strDate, dtf); } 2、 ZonedDate、ZonedTime、ZonedDateTime Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-24 17:55:02 "},"spring/00-首页.html":{"url":"spring/00-首页.html","title":"Spring","keywords":"","body":" Spring全家桶 Spring全家桶介绍 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-16 22:14:34 "},"spring/01-Spring Boot基础.html":{"url":"spring/01-Spring Boot基础.html","title":"Spring Boot基础","keywords":"","body":" ​Spring boot基础 一、Yaml配置 1、双引号和单引号的关系 ​ \"\"双引号:不会转义字符串里面的特殊字符，特殊字符会作为本身想表达的意思 ​ \"name\": \"zhangsan \\n lisi\"：输出为zhangsan 换行 lisi ​ ''单引号：会转义特殊字符，字符串最终只是一个普通的字符串数据 ​ \"name\": \"zhangsan \\n lisi\"：输出为zhangsan \\n lisi 2、数组元素（list、set）,两种表示方法 pets1: - cat - dog - pig pets2: [pig,cat,dog] 3、@Value和@ConfigurationProperties @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 单个指定属性注入 松散绑定 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 说明： 1、松散绑定，是指属性可以通过中杠和驼峰格式直接映射；last-name,lastName 2、SpEL表达式， @Value(\"${xx.xx.xx}\")，映射配置文件 @Value(\"#{20*3}\"), 计算式最后映射到字段的值是60 @Value(\"true\"), 布尔型 3、JSR303数据校验，@Validated标签 @Commponment @ConfigurationProperties(profix = \"person\") @Validates public class person{ // 进行字段email格式校验 @Email private String email; } 使用选择： 如果是业务逻辑中获取某个配置文件的值时选择使用@Value 如果是编写了映射类与配置文件进行映射就使用@ConfigurationProperties 4、@PropertySource和@ImportResource @propertySource：加载指定的配置文件，而不通过全局配置文件（application.yml）中获取 @Commonpent @PropertySource(value = {\"classpath:person.yml\"}) public class person{ } @ImportResource：导入Spring配置文件，让配置文件里的内容生效 @ImportResource(local = {\"classpath:person.xml\"}) @SpringBootApplication public class Application{ } SpringBoot推荐使用@Bean对第三方主键进行注入 /** * @Configuration指明该对象为配置类用来替代Spring的配置文件(xx.xml) */ @Configuration public class MyApplicationConfig{ @Bean public HelloService helloService() { return new HelloService(); } } 5、配置文件占位符 1、随机数 ${random.int}、${random.long}、${random.int(10)}、${random.int(1024, 3213456)} 2、占位符获取之前配置的值，如果没有可以使用冒号指定默认值 person.last-name=张三 person.dog.name=${person.last-name:张三}_dog 6、多环境配置文件配置Profile 1、多Profile文件配置 配置多个application-{profile}.properties/yml，默认使用application.properties/yml 2、Yml支持多文档块配置 在yml配置文件中用---分隔一个文档块 server: port: 8081 spring profile: active:dev --- server: port: 8082 spring: profiles: dev # 开发环境 --- server: port: 8082 spring: profiles: prod # 正式环境 3、Profile文件激活方式 1、在配置文件中直接指定，spring.profile.active=dev 2、命令行方式：java -jar test.jar --spring.profile.active=dev 3、虚拟机方式：-Dspring.profile.active=dev 7、配置文件加载位置 Springboot启动时扫描以下位置的application.properties或者application.yml文件作为默认配置文件 -file:../config -file:../ -classpath:../config -classpath:../ 优先级由高到低，高优先级的配置会覆盖低优先级的配置,Springboot会从这四个文件夹位置加载配置文件，形成互补配置 可以通过spring.config.location修改配置文件加载位置： java -jar test.jar --spring.config.location=d:/config/application.properties(yml) 8、Springboot外部配置加载顺序 Springboot可以从以下位置加载配置，优先级由高到底，并形成互补配置 1、命令行配置 java -jar test.jar --server.port=9090 2、由jar包外到jar包内查找application.properties(yml) 9、自动配置 10、@Conditional和自动配置报告 @Conditional注解的作用是作为条件判断，使得自动配置生效 @Conditional扩展注释 作用（判断是否满足当前条件） @ConditionalOnjava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean @ConditionalOnMissBean 容器中不存在指定Bean @ConditionalOnExpression 满足SpEL表达式 @ConditionalOnClass 系统中指定的类 @ConditionalOnMissClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean,或者这个bean是首选 @ConditionalOnProperty 系统中指定的值是否有确定的值 @ConditionalOnResource 类路径下是否有指定资源文件 @ConditionalOnWebApplication 当前时web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 配置类需要在一定条件下才会自动配置，可以通过打开Springboot的Debug模式来查看自动配置的类的信息 debug=true 二、日志配置 1、SpringBoot日志框架：slf4j抽象日志接口+logback日志实现类组合 2、SpringBoot日志框架：可以通过扩展包将log4j等日志框架实现适配slf4j接口 3、对于旧框架引用的日志框架，slf4j提供了对应的包将旧框架的日志的jar包进行替换 4、logging.file：指定输出日志文件 5、logging.path：指定输出日志的路径(项目中常用) 6、log输出级别(由低到高) log.trace(\"\"); log.debug(\"\"); log.info(\"\"); log.warn(\"\"); log.error(\"\"); 7、日志指定配置 不同日志框架，在SpringBoot中定义log配置文件名称规则 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logbak.xml：会被日志框架直接识别 logbak-srping.xml：不会被日志框架直接识别，会被Spring-Boot识别，可以使用SpringBoot中使用一些高级功能，springprofile 标签 // 开发环境输出的日志内容 ..... 其他日志框架的配置文件同样使用*-spring.xml的名称规则 三、WEB开发 1、SpringBoot静态资源映射规则 @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { if (!this.resourceProperties.isAddMappings()) { logger.debug(\"Default resource handling disabled\"); return; } Duration cachePeriod =this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); if (!registry.hasMappingForPattern(\"/webjars/**\")) { customizeResourceHandlerRegistration(registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\") .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } String staticPathPattern =this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } } // 欢迎页 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) { WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider)); welcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations()); return welcomePageHandlerMapping; } 1.所有webjars/**都去classpath:/META-INF/resources/webjars/找资源 webjars：以jar包的形式引入静态资源（已经将第三方前端插件封装成jar，用mevean进行依赖） 依赖包地址：https://www.webjars.org/ org.webjars jquery 3.3.1 2./**访问当前项目的任何资源。（静态资源） \"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" 对应的文件目录结构 3.欢迎页：静态资源目录下的所有index.html页面，被/**映射： localhost:8080/ 找到index页面 4.所有的**/favicon.ico都在静态资源目录下找，favicon.ico是指菜单栏图标 5.Spring Boot修改静态资源路径 spring.resources.static-locations=classpath:/hello/ 2、SpringBoot MVC自动配置（WebMvcAutoConfiguration） https://docs.spring.io/spring-boot/docs/2.1.17.RELEASE/reference/html/boot-features-developing-web-applications.html Spring Boot 自动配置好了Spring MVC. 以下是SpringBoot的Spring MVC默认配置: Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器，通过方法返回值得到对应的View对象） ContentNegotiatingViewResolver ：组合所有的视图解析器 Support for serving static resources, including support for WebJars (covered later in this document)). 静态资源文件夹路径，WebJars Static index.html support. 静态首页访问 Custom Favicon support (covered later in this document). 静态资源favicon.ico 自动注册 Converter, GenericConverter, and Formatter beans. Converter：类型转换器 Formatter ：格式化器（日期格式化） Support for HttpMessageConverters (covered later in this document). HttpMessageConverter：SpringMVC用来转换Http请求和相应 自己给容器中添加HttpMessageConverter，只需要将自己的组件注册到容器中（@Bean,@Component） Automatic registration of MessageCodesResolver (covered later in this document). MessageCodesResolver：定义错误代码配置类 Automatic use of a ConfigurableWebBindingInitializer bean (covered later in this document). 3、SpringBoot MVC扩展配置 If you want to keep Spring Boot MVC features and you want to add additional MVC configuration (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, you can declare a WebMvcRegistrationsAdapter instance to provide such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 编写一个配置类@Configuration，实现WebMvcConfigurer重写相应的方法，不要添加@EnableWebMvc注解，即保留SpringBoot默认配置，也包含自己的配置 @Configuration public class MyConfig implements WebMvcConfigurer { @Override public void addViewControllers(ViewControllerRegistry registry) { // 效果浏览器发送/hello请求，返回成功页面 registry.addViewController(\"/hello\").setViewName(\"success\"); } } @EnableWebMvc：全部取消SpringBoot相关MVC自动配置。 3、如何修改SpringBoot的默认配置 模式： 1)、SpringBoot在自动配置组件的时候，先判断容器中有没有存在用户自己创建的组件（@Bean,@Component）,如果没有才会自动配置；如果有些组件可以有多个组件，将用户配置和自己默认的组合起来使用。用户如果要自定义组件直接注入到容器中即可。 2）、SpringBoot提供了很多xxxConfigure提供自定义配置 3）、SpringBoot提供了很多xxxCustomizer帮助我们进行定制配置 4、配置嵌入式Servlet容器 SpringBoot默认使用tomcat作为嵌入式Servlet容器 1、如何定制和修改Servlet容器的配置 1）、修改和server有关的配置(ServerProperties),对于不同容器也可以进行特殊配置 server.port=9080 // 对不同容器进行特殊化配置 server.tomcat.xxx=xxx 2)、编写一个WebServerFactoryCustomizer，嵌入到Servlet容器的定制器；来修改Servlet容器的配置 5、注册Servlet、Filter、Listener ServletRegistrationBean // 注册自己的Servlet,设置拦截路径 @Bean public ServletRegistrationBean myServlet() { ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(), \"/hello\"); return registrationBean; } FilterRegistrationBean @Bean public FilterRegistrationBean myFilter() { FilterRegistrationBean registrationBean = new FilterRegistrationBean(); // 设置过滤器 registrationBean.setFilter(new MyFilter()); // 设置过滤地址 registrationBean.setUrlPatterns(Arrays.asList(\"/hello\",\"/curd\")); return registrationBean; } ServletListenerRegistrationBean @Bean public ServletListenerRegistrationBean myListener() { ServletListenerRegistrationBean registrationBean = new ServletListenerRegistrationBean(); // 注册自己厂家的监听器 registrationBean.setListener(new MyListener()); return registrationBean; } Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-01-16 22:16:51 "},"devtool/00-首页.html":{"url":"devtool/00-首页.html","title":"开发工具","keywords":"","body":" 开发工具 ​ 开发工具学习 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-06-06 11:16:02 "},"devtool/nifi/00-nifi.html":{"url":"devtool/nifi/00-nifi.html","title":"nifi","keywords":"","body":" Nifi应用 一、Nifi简介 1、Nifi是什么 一个用户友好，可扩展且可靠的，专为处理数据流而诞生的，强大的数据处理工具, 把数据处理过程中可能需要经历的步骤都封装成一个个处理器，可以让我们随意搭配使用 2、我们用来做什么 数据梳理流程，http://192.168.60.138:8089/nifi/ 3、术语，在overview FlowFile:流文件 Processor：（处理器）每个组件 Connection：连接提供处理器之间的实际链接。它们充当队列，允许各种进程以不同的速率进行交互。这些队列可以动态地划分优先级，并且可以有负载的上限，从而实现背压。 Flow Controller：后台调度器 流控制器维护流程如何连接和管理所有进程使用的线程及其分配的知识。流控制器充当代理，促进处理器之间的流文件交换。 Process Group：进程组是一组特定的进程及其连接，可以通过输入端口接收数据，也可以通过输出端口发送数据。以这种方式，流程组允许通过组合其他组件来创建全新的组件。 几个示例流程 http://192.168.60.138:8089/nifi/?processGroupId=338a8267-0178-1000-a846-f5549c2f7eff&componentIds= 几个常用的控制服务 Controller Services Controller Services:A ControllerService provides shared state and functionality across Processors, other ControllerServices, and ReportingTasks within a single JVM. An example use case may include loading a very large dataset into memory. By performing this work in a ControllerService, the data can be loaded once and be exposed to all Processors via this service, rather than requiring many different Processors to load the dataset themselves. 比如： DBCPConnectionPool，RedisConnectionPoolService 二、常用的组件-Processors 2.1、数据转换 2.1.1 EncryptContent 2.1.2 ReplaceText 描述： ​ 使用其他值替换匹配正则表达式的流文件部分内容，从而更新流文件的内容。 属性配置： 应用场景： ​ 使用正则表达式，来逐行或者全文本替换文件流内容，往往用于业务逻辑处理。 示例说明： 1、流文件内容 2、全文本替换，配置如下 ​ (?s)(^.*$)匹配所有值，选择正则匹配替换，全文本替换， 结果： 3、逐行替换，配置如下 结果： 2.2、路由和调解： 2.2.1 DistributeLoad 描述： ​ 该处理器根据分发策略将流文件分发给下游处理器。如果使用循环策略，默认情况下为每个目的地分配1个权重(均匀分布)。当然，权重与 relationship都是灵活可配的，比如自定义 属性名‘5’，值‘2’，那么relationship为‘5’的权重为2 属性配置： 动态属性： 应用场景： ​ 按权重向下游多个处理器分发数据。在单个流程处理数据达到瓶颈，而整体环境资源充足，这种情况有可能需要多个流程来分担数据处理压力。而该处理器充当一个分发数据的角色；（注：与connection的Load Balance要区分开） 示例说明： ​ 模拟数据发送到3个处理流程中 配置信息：关系权重值越大，权重越高，分配的流文件越多 2.2.2 RouteOnAttribute 描述： ​ 该处理器使用属性表达式语言，根据流文件的属性去计算然后进行路由。 属性配置： 动态属性： 应用场景： ​ 该处理器往往用于判断流文件属性 示例说明： ​ 判断属性中多个值是否为空，不同判断结果执行不同逻辑 自定义paramError属性 ${lastest.pkName:isEmpty():or(${lastest.pkValue:isEmpty()}):or(${lastest.tsValue:isEmpty()}):or(${lastest.tsName:isEmpty()})} 输入流属性如下，要求非空的属性中有空值： 结果如下：路由到paramError关系 2.2.3 RouteOnContent 描述： ​ 该处理器使用正则表达式去匹配流文件的内容，并将流文件路由到正则表达式所匹配的relation。在用户自定义的属性上添加正则表达式，其中属性的名称是关系的名称，值是一个正则表达式，用于匹配流文件内容。用户定义的属性支持属性表达式语言，但是表达式计算的结果被解释为文字值，而不是正则表达式。 属性配置： 动态属性： 应用场景： ​ 该处理器用于路由，控制流文件去向。 示例说明： ​ 比如进行一次Http请求，请求返回的数据中有字符串 \"success\":true 表名此次请求成功 2.3、数据库操作： 2.3.1 QueryDatabaseTable 描述： ​ 生成SQL select查询，或使用提供的语句，并执行该查询以获取指定的最大值列中的值大于先前看到的最大值的所有行。查询结果将转换为Avro格式。多个属性支持表达式语言，但不允许传入连接。变量注册表可用于为包含表达式语言的任何属性提供值。如果需要利用流文件属性来执行这些查询，则可以使用GenerateTableFetch和/或ExecuteSQL处理器来实现此目的。使用流式处理，因此支持任意大的结果集。可以使用标准的调度方法，将此处理器调度为在计时器或cron表达式上运行。此处理器仅在主节点上运行。流文件属性'querydbtable.row.count'表示选择了多少行。 属性配置：属性查看官方文档 2.3.2 ConvertJSONToSQL 描述： ​ 将json转换成可执行的SQL；json要求为flat型的，就理解为是简单的key-value形式，没有过深的结构；json是单条，数组都可以；数组的json时，输出是若干个单条json的SQL语句； 属性配置： JDBC Connection Pool：数据库连接池HiveConnectionPool，DBCPConnectionPool，DBCPConnectionPoolLookup Statement Type：UPDATE INSERT DELETE Table Name：表名 Catalog Name：设置为空就行； Schema Name：看数据库类型配置，比如gp之类的就有schema Translate Field Names：如果为真，处理器将尝试将JSON字段名转换为指定表的适当列名。如果为false, JSON字段名必须与列名完全匹配，否则不会更新列 Unmatched Field Behavior：一个字段不匹配，如何处理；可选忽略不匹配字段，或者直接报错； Unmatched Column Behavior：所有字段都不匹配，如何处理； Update Keys：惟一地标识数据库中用于UPDATE语句的行。如果语句类型为 UPDATE，且未设置此属性，则使用表的主键。在这种情况下，如果不存在主键，那么如果将不匹配的列行为设置为failed，那么转换到SQL的操作将失败。如果语句类型为INSERT，则忽略此属性 Quote Column Identifiers：引用列标识符；启用此选项将导致引用所有列名，允许在表中使用保留字作为列名。 Quote Table Identifiers：同上 SQL Parameter Attribute Prefix：SQL参数属性前缀，sql.args.1.value 那个sql就是前缀 Table Schema Cache Size：指定应缓存多少表架构 注意 ​ 大量数据插入，这个Processor的效率很低的，为什么这么说呢，一个流的数据如果是json，也应该是json数组，但一个json数组通过这个processor得到的结果是若干个insert语句，每一个insert语句中只有一条数据；可以改进成insert into table （）values （）（）。。。的形式；也可以使用PutDatabaseRecord 做大量数据的insert，PutDatabaseRecord的优势是内置reader，减少了流程的中间落地 2.3.3 ExecuteSQL 描述： 该处理器执行SQL语句，返回avro格式数据。处理器使用流式处理，因此支持任意大的结果集。处理器可以使用标准调度方法将此处理器调度为在计时器或cron表达式上运行，也可以由传入的流文件触发。SQL语句来源可以来自该处理器属性SQL select query，也可以来自上一个处理器的输出流（UTF-8格式）（GenerateTableFetch，ConvertJsonToSql等等生成的流内容中的SQL语句，类似于insert into。。。value （？。。。），这个？的值是存在于流属性中的：sql.args.N.value sql.args.N.type ，ExecuteSQL会自动装配并执行） 属性配置： 注意： Max Rows Per Flow File ：每个流文件包含的数据条数； Output Batch Size：几个流文件同时输出到下个流程； 2.3.4 PutSQL 描述： ​ 执行SQL更新或插入命令。传入流文件的内容应该是要执行的SQL命令。SQL命令可以使用？转义参数。在这种情况下，要使用的参数必须作为具有命名约定sql.args.N.type和sql.args.N.value的FlowFile属性存在，其中N是正整数。sql.args.N.type应该是一个表示JDBC类型的数字。流文件的内容应为UTF-8格式。 属性配置： JDBC Connection Pool：指定要用于将JSON消息转换为SQL语句的JDBC连接池。连接池是确定适当的数据库列类型所必需的。 SQL Statement：要执行的SQL语句。语句可以是空的、常量值，也可以使用表达式语言从属性构建。如果指定了此属性，则无论传入流文件的内容如何，都将使用它。如果此属性为空，则传入流文件的内容应包含由处理器向数据库发出的有效SQL语句。 Support Fragmented Transactions：如果为true，则当此处理器使用流文件时，处理器将首先检查该流文件的fragment.identifier和fragment.count属性。如果fragment.count值大于1，则处理器将不处理任何具有该fragment.identifier的流文件，直到所有流文件都可用；此时，它将以FlowFiles的fragment.index属性指定的顺序，将具有该fragment.identifier的所有流文件作为单个事务进行处理。这提供了这些SQL语句的原子性。一旦此事务的任何语句在执行时抛出异常，此事务将回滚。当事务回滚发生时，这些流文件都不会路由到“success”。如果设置为true，这些流文件将保留在输入关系中。当设置为false时，如果这些流文件中的任何一个将路由到“retry”，则所有这些流文件都将路由到“retry”。否则，它们将路由到“Failure”。如果该值为false，这些属性将被忽略，更新将独立于其他属性进行。 Database Session AutoCommit：要在正在使用的数据库连接上设置的自动提交模式。如果设置为false，操作将显式提交或回滚（分别基于成功或失败），如果设置为true，驱动程序/数据库将处理提交/回滚。 Transaction Timeout：如果属性设置为true，则指定在将具有该标识符的所有流文件传输到“failure”关系之前，等待特定fragment.identifier属性的所有流文件到达的时间 Batch Size：在单个事务中放入数据库的首选流文件数 Obtain Generated Keys：如果为true，则数据库自动生成的任何键都将添加到使用sql.generate.key属性生成它的流文件中。这可能会导致性能稍慢，并非所有数据库都支持。 Rollback On Failure：指定如何处理错误。默认情况下（false），如果处理流文件时发生错误，则流文件将根据错误类型路由到“失败”或“重试”关系，并且处理器可以继续处理下一个流文件。相反，您可能希望回滚当前处理的流文件并立即停止进一步的处理。在这种情况下，可以通过启用此“失败时回滚”属性来实现。如果启用，则失败的流文件将保留在输入关系中，而不会对其进行惩罚并重复处理，直到成功处理或通过其他方式删除为止。设置足够的“屈服持续时间”以避免过于频繁地重试是很重要的。 2.3.5 ConvertJSONToAvro 描述： ​ 该处理器根据Avro schema将JSON转换为Avro。 属性配置： 应用场景： 该处理器根据Avro schema将JSON转换为Avro。 在使用 Kite 获取 avro schema时，需要配置Hadoop配置文件； 示例说明： 1：每次只 接收一个Json数据 ，无法处理Json数组 。 输入json： 配置：手动配置schema 或者上下文attribute传递schema 结果： 2.4、属性提取： 2.4.1 EvaluateJsonPath 描述： ​ 该处理器根据流文件的内容计算一个或多个JsonPath表达式。这些表达式的结果被写入到FlowFile属性，或者写入到FlowFile本身的内容中，这取决于处理器的配置。通过添加用户自定义的属性来输入jsonpath，添加的属性的名称映射到输出流中的属性名称(如果目标是flowfile-attribute;否则，属性名将被忽略)。属性的值必须是有效的JsonPath表达式。“auto-detect”的返回类型将根据配置的目标进行确定。当“Destination”被设置为“flowfile-attribute”时，将使用“scalar”的返回类型。当“Destination”被设置为“flowfile-content”时，将使用“JSON”返回类型。如果JsonPath计算为JSON数组或JSON对象，并且返回类型设置为“scalar”，则流文件将不进行修改，并将路由到失败。如果所提供的JsonPath计算为指定的值，JSON的返回类型可以返回“scalar”。如果目标是“flowfile-content”，并且JsonPath没有计算到一个已定义的路径，那么流文件将被路由到“unmatched”，无需修改其内容。如果目标是“flowfile-attribute”，而表达式不匹配任何内容，那么将使用空字符串创建属性作为值，并且FlowFile将始终被路由到“matched”。 属性配置： 应用场景： ​ 通常当需要从流文件json中提取某些数据作为流属性时，使用此处理器；或者从流文件json内容中提取一部分内容作为下一个流文件内容，使用此处理器。 示例说明： ​ 1：提取流文件json内容，作为输出流的属性。（注意：当输出选择flowfile-attribute时，及时jsonpath匹配不到值，流文件也会路由到matched） 2：提取流文件json内容，作为输出流的内容。（注意：当选择flowfile-content时，用户只能自定义添加一个属性；如果jsonPath匹配不到，会路由到unmatched） 2.4.2 UpdateAttribute 描述： ​ 该处理器使用属性表达式语言更新流文件的属性，并且/或则基于正则表达式删除属性 属性配置： 应用场景： 该处理器基本用法最为常用，及增加，修改或删除流属性；此处理器使用用户添加的属性或规则更新FlowFile的属性。有三种方法可以使用此处理器添加或修改属性。一种方法是“基本用法”; 默认更改通过处理器的每个FlowFile的匹配的属性。第二种方式是“高级用法”; 可以进行条件属性更改，只有在满足特定条件时才会影响FlowFile。可以在同一处理器中同时使用这两种方法。第三种方式是“删除属性表达式”; 允许提供正则表达式，并且将删除匹配的任何属性。请注意，“删除属性表达式”将取代发生的任何更新。如果现有属性与“删除属性表达式”匹配，则无论是否更新，都将删除该属性。也就是说，“删除属性表达式”仅适用于输入FlowFile中存在的属性，如果属性是由此处理器添加的，则“删除属性表达式”将不会匹配到它。 示例说明： 1：基本用法增加一个属性 2：高级用法，添加规则条件，符合条件时update指定的属性值 点击ADVANCED 3：高级用法 存储状态,记录通过该处理器的数据流总和 2.4.3 AttributesToCSV 描述： ​ 该处理器将输入流文件属性转成CSV表示形式。生成的CSV可以被写入一个名为“CSVAttributes”的新属性，也可以作为内容写入到流文件中。如果属性值包含逗号、换行符或双引号，则属性值将用双引号转义。属性值中的任何双引号字符都用另一个双引号转义。 属性配置： 应用场景： ​ 该处理器就是将流文件的若干属性转成csv数据，输出到输出流文件的属性或者内容当中 。 示例说明： 1：如图为GenerateFlowFile生成的流文件，AttributesToCSV配置csv输出到流属性中，csv包含核心属性 ，包含schema 配置如下： 结果为(AttributesToCSV的数据流属性)： 2：例子1中同样的配置，但输出到输出流的content中 结果为： 2.4.4 AttributesToJSON 描述： ​ 该处理器将输入流文件属性转成JSON表示形式。生成的JSON可以被写入一个名为“JSONAttributes”的新属性，也可以作为内容写入到流文件中。 属性配置： 应用场景： ​ 该处理器就是将流文件的若干属性转成JSON数据，输出到输出流文件的属性或者内容当中 。 示例说明： 1：如图为GenerateFlowFile生成的流文件，AttributesToJSON配置json输出到流属性中，包含核心属性 配置如下： 结果为： 2：例子1中同样的配置，但json输出到输出流的content中 结果： 2.5、系统交互： 目前没用 2.6、数据摄取： 2.6.1 GET 2.6.2 ConsumeKafka 描述： ​ Kafka消费程序 2.6.3 ScrollElasticsearchHttp 描述： ​ 拉起ES数据 2.7、数据出口/发送数据: 2.7.1 PUT 2.7.2 PutKafka 2.8、拆分和聚合: 2.8.1 SplitJson 描述： ​ 该处理器使用JsonPath表达式指定需要的数组元素，将JSON数组分割为多个单独的流文件。每个生成的流文件都由指定数组的一个元素组成，并传输到关系“split”，原始文件传输到关系“original”。如果没有找到指定的JsonPath，或者没有对数组元素求值，则将原始文件路由到“failure”，不会生成任何文件。 属性配置： 应用场景： ​ 该处理器主要用于分割json数组，灵活运用时也可做数据清洗(比如需要抽取json中某一个字段)。 示例说明： 1:下面是该处理器应用最多的情况，如下图为一json数组 在SplitJson中配置JsonPath为 $.* (匹配数组任意元素) split关系中输出3个分割文件，original关系中输出被分割原文件。 2：举例说明该处理器的复杂使用，如下图为一多层次结构json数组，需要分割取出json数组中的father字段。 配置JsonPath为$.*.family.father 结果： 2.8.2 MergeRecord 描述： ​ 此处理器将多个面向记录的流文件合并到一个包含输入流文件所有记录的流文件中。这个处理器的工作原理是创建“文件箱”，然后将流文件添加到这些文件箱中，直到它们满为止。一旦一个箱子满了，所有的流文件将合并成一个输出流文件，并且该流文件将被路由到“合并”关系。一个垃圾箱可能由许多“like flowfile”组成。为了将两个流文件视为“类似于流文件”，它们必须具有相同的架构（由记录读取器标识），并且如果设置了属性，则指定属性的值必须相同。有关详细信息，请参阅处理器用法和其他详细信息。 2.9、HTTP: 2.9.1 GetHTTP 描述： ​ 请注意，此处理器已弃用，可能会在不久的将来被删除。改用InvokeHTTP。从HTTP或HTTPS URL获取数据并将数据写入流文件的内容。一旦获取了内容，ETag和最后修改的日期就会被记住（如果web服务器支持这些概念的话）。这允许处理器仅在远程数据已更改或状态清除之前获取新数据。也就是说，一旦从给定的URL获取了内容，在远程服务器上的内容发生更改之前，不会再次获取该内容。注意，由于状态管理的限制，存储的“last modified”和etag字段永远不会过期。如果GetHttp中的URL使用的表达式语言是无界的，则可能会发生内存不足错误。 2.9.2 ListenHTTP 描述： ​ 启动HTTP服务器并侦听给定的基本路径，以将传入的请求转换为流文件。服务的默认URI将是http://{hostname}:{port}/contentListener。只支持HEAD和POST请求。GET、PUT和DELETE将导致错误和HTTP响应状态代码405。在/healthcheck上支持GET。如果服务可用，则返回“200ok”，内容为“OK”。可以将运行状况检查功能配置为可通过其他端口访问。有关详细信息，请参阅“健康检查请求的侦听端口”属性的文档。 2.9.3 InvokeHTTP 描述： ​ 可以与可配置的HTTP端点交互的HTTP客户端处理器。目标URL和HTTP方法是可配置的。FlowFile属性被转换为HTTP头，FlowFile内容作为请求的主体（如果HTTP方法是PUT、POST或PATCH）。 2.9.4 PostHTTP 描述： ​ 请注意，此处理器已弃用，可能会在不久的将来被删除。改用InvokeHTTP。使用流文件的内容执行HTTP Post。使用最大连接数等于可能端点数乘以并发任务配置的连接池。 2.10、网络服务： 目前没用 2.11、其他： 2.11.1 ExecuteScript 描述： ​ 实验-执行给定流文件和进程会话的脚本。脚本负责处理传入的流文件（例如，传输到SUCCESS或remove）以及由脚本创建的任何流文件。如果处理不完整或不正确，会话将回滚。实验：持续使用的影响尚未得到验证。 2.11.2 AttributeRollingWindow 描述： ​ 本组件在一个时间窗口内，计算每一个流经的流文件的对应的NIFI表达式，然后把这些值记录在组件的state中。在这个时间窗口内的流文件，会在流属性中记录组件处理它时一共处理了多少的流文件，NIFI表达式计算结果的总和均值。 属性配置： 2.11.3 Base64EncodeContent 描述： ​ 该处理器对base64和base64之间的内容进行编码或解码 属性配置： 2.11.4 LogAttribute 描述： ​ 该处理器流属性输出到日志中。 属性配置： 应用场景： ​ 用于输出流中的某些属性到日志中。 示例说明： 1：将某属性输出到日志当中 结果： 2.11.5 LogMessage 描述： ​ 该处理器发出指定日志级别的日志消息。 属性配置： 应用场景： ​ 用于输出日志，比如一个流程处理完毕，最终的流文件可以触发此流文件，打出日志。 示例说明： 1:使用此处理器在日志中打印出流中的某个属性 结果为： 2.11.6 GenerateFlowFile 描述： ​ 该处理器使用随机数据或自定义内容创建流文件。GenerateFlowFile用于负载测试、配置和仿真。 属性配置： 应用场景： 该处理器多用于测试，配置生成设计人员所需要的特定数据，模拟数据来源或者压力测试、负载测试；某些场景中可以作为配置灵活使用，比如设计人员想设计一个流程查询多个表，表名就可以做出json数组配置到Custom Text，之后再使用其他相关处理器生成含有不同表名属性的多个流文件，就可以实现一个流程查询多表。(额外延伸，也可以在变量注册表、缓存保存配置，通过不同的配置读取不同的表) 示例说明： 1：该处理器生成流文件固只能作为所设计流程的第一个处理器，不允许作为其他处理器传入连接关系。 2：设置批量输出流文件，设置数据格式为Text，并且在Custom Text使用了随机数表达式。 此时每次输出10个流文件，表达式${random():mod(10):plus(1)}只执行一次，10个流文件中的文本内容是相同的。 三、官网介绍 地址：https://nifi.apache.org/docs.html general： overview：概览 相关概念，架构，特性 getting started：开始入门，安装，整体面板介绍，处理器使用，处理器分类，属性操作，使用表达式语言，模板操作，nifi监控，数据来源到结束说明页面 user guide ：具体的每个操作的说明，比如处理器每个面板的说明，流程参数设置如何使用等 expression language guide：所有表达式语言 recordpath：处理数据，这个目前没用到 Admin Guide：安装、配置、安全认证，升级等 Toolkit Guide：工具指南，nifi工具包的指南 客户端命令等 depveloper: rest api: /nifi-api，调用nifi提供的rest接口，比如自动生成流程，在规定位置生成组件，修改组件树形等 deveplore guide: 如何开发nifi组件，control service等，组件代码的解释等 NiFi深入： 仓库，flowfile的生命周期，等 Processors 每个处理器的说明文档 Controller Services 控制服务 Reporting Tasks 报告任务 四、安装 Admin Guide 下载地址 常用参数，目录情况 启动等命令 重要的xml文件 五、自定义组件开发 六、问题处理 积压之类 模板上传下载 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-05-04 11:50:09 "},"devtool/docker/00-Docker基础.html":{"url":"devtool/docker/00-Docker基础.html","title":"docker","keywords":"","body":" Docker基础 一、Docker概要 1.1 Docker为什么会出现？ 1.2 Docker相应材料 ​ 官方地址：https://www.docker.com/ 文档地址：https://docs.docker.com/ ​ 仓库地址：https://www.docker.com/products/docker-hub 1.3 Docker与虚拟机的比较 传统虚拟机虚拟出一条硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件 容器内的应用直接运行在宿主机内核，容器自己没有内核，也没有虚拟相应的硬件，所以更轻便 每个容器间是相互隔离，每个容器内都有一个属于自己的文件系统，互不影响 1.4 Docker优势 应用更快速的交付和部署 更便捷的升级和扩容 更简单的系统运维 更高效的计算资源利用 1.5 Docker中的名称概念 1、镜像（Image） ​ docker镜像好比一个模板，可以通过这个模板来创建一个容器服务 2、容器(Container) ​ Docker通过容器技术，独立运行一个或者一组应用，通过镜像来创建的 3、仓库(Repository) ​ 仓库就是存放镜像的地方 二、Docker安装 1.1 安装文档 文档地址：https://docs.docker.com/engine/install 根据要安装的系统查看相应的安装说明 1.2 安装步骤 1、卸载旧的版本 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 2、安装需要的安装包 yum install -y yum-utils 3、设置镜像仓库 # 国外镜像地址 yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 阿里云镜像地址 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4、安装yum软件索引 yum makecache fast 5、安装Docker引擎 # docker-ce：是指社区版（**官方推荐使用**） docker-ee：指企业版 yum install docker-ce docker-ce-cli containerd.io 6、启动Docker systemctl start docker 7、查看Docker信息 docker version 8、运行Hello World docker run hello-world ​ 如果程序不存在会自动下载hello-word的镜像，然后在执行 9、删除Docker ![docker-1](01-Docker基础.assets/docker-1.png)# 1、删除Docker服务 yum remove docker-ce docker-ce-cli containerd.io # 2、删除相应的文件 rm -rf /var/lib/docker rm -rf /var/lib/containerd # /var/lib/docker为Docker默认的工作路径 1.3 Docker工作原理 1、Docker如何工作 ​ Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上，通过Socket从客户端访问；DockerServer接收到DockerClient的指令，就会执行这个命令。 2、Docker比Vm更快 Docker有着比虚拟机更少的抽象层； Docker利用的宿主机的内核，Vm需要Guest OS；Docker不需要像虚拟机一样重新加载一个操作系统内核。 三、 Docker命令 3.1 帮助命令： docker version # 显示docker的版本信息 docker info # 显示docker的系统信息，包括镜像和容器的数量 docker --help # 帮助命令 ​ 帮助文档地址：https://docs.docker.com/reference/ 3.2 镜像命令 docker images 查看本地Docker镜像 root@192.168.56.101:~# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest d1165f221234 2 months ago 13.3kB 解释： REPOSITORY 镜像的仓库源 TAG 镜像的版本 IMAGE ID 镜像的ID SIZE 镜像大小 其他参数: -a, --all # 显示所有镜像 -q, --quiet # 显示镜像ID # 示例 root@192.168.56.101:~# docker images -q d1165f221234 显示所有镜像的ID root@192.168.56.101:~# docker images -aq d1165f221234 docker search 搜索Docker镜像 root@192.168.56.101:~# docker search mysql NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 10842 [OK] mariadb MariaDB Server is a high performing open sou… 4091 [OK] 参数： -f, --filter # 过滤镜像条件 示例：（查询Mysql的STARS值大于3000的镜像） root@192.168.56.101:~# docker search mysql --filter=STARS=3000 NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 10842 [OK] mariadb MariaDB Server is a high performing open sou… 4091 [OK] Docker pull 下载镜像 # 下载镜像 docker pull 镜像名[:tar] root@192.168.56.101:~# docker pull mysql root@192.168.56.101:~# docker pull ./io/library/mysql:last Docker rmi 删除镜像 删除单个镜像 root@192.168.56.101:~# docker rmi 镜像ID 删除多个镜像 root@192.168.56.101:~# docker rmi 镜像ID 镜像ID 镜像ID 删除所有镜像 root@192.168.56.101:~# docker rmi $(docker images -aq) 3.3 容器命令 ​ 说明：镜像必须运行后才会有容器 1、新建容器并启动 docker run [可选参数] image # 参数说明 --name=\"Name\" 容器名字 tomcat1 tomcat2,用来区分容器 -d 后台执行 -it 使用交互方式运行，进入容器查看内容 -p 指定容器的端口 -p ip:主机端口映射:容器端口 -p 主机端口:容器端口（常用） -p 容器端口 -P(大写) 指定随意端口 测试： # 启动并进入到docker容器（/bin/bash是容器的控制台） root@192.168.56.101:~# docker run -it centos /bin/bash [root@7bb0b0f0c05a /]# ls # 查看容器内的centos bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var # 退出容器 [root@7bb0b0f0c05a /]# exit exit 2、查看所有运行的容器 # docker ps 命令 # 列出所有运行的容器 -a # 列出当前运行和历史运行的容器 -n=? # 显示最近创建的容器,n表示显示的个数 -q # 显示容器的编号 root@192.168.56.101:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3、退出容器 exit # 容器停止运行并退出 ctrl + P + Q # 容器不停止退出 4、删除容器 docker rm 容器ID # 根据ID删除容器,不能删除正在运行的容器 docker rm -f $(docker ps-aq) # 删除所有容器 docker ps -a -q|xargs docker rm # 删除所有容器 5、启动和停止容器的操作 docker start 容器ID # 启动容器 docker restart 容器ID # 重启容器 docker stop 容器ID # 停止容器 docker kill 容器ID # 强制停止容器 3.4 其他命令 1、后台启动镜像 # 命令 docker run -dit 镜像名 /bin/bash # 在使用-d启动镜像时同样需要指定控制台信息（/bin/bash），否则容器会判断没有可执行程序而直接退出 2、查看容器日志 docker logs --help # 查看帮助 # 查看容器10条日志 docker logs -tf --tail 10 容器ID 3、查看容器进程信息 docker top 容器ID 4、查看镜像元数据处理 docker inspect 容器ID 5、进入运行容器 # 命令1 docker exec -it 容器ID /bin/bash # 命令2 docker attach 容器ID # 两个命令的区别 docker exec # 进入容器后开启一个新的终端，可以在里面做操作(常用) docker attach # 进入容器正在执行的终端，不会启动新的进程 6、容器内的文件拷贝到宿主主机 docker cp 容器ID:容器路径 宿主主机路径 7、提交自己的镜像文件 # 命令 docker commit -m='提交的描述内容' -a='作者' 容器ID 目标镜像名称:[版本信息] 3.5 练习 安装nginx # 1、查找nginx,通过命令或者docker hub查看 docker search nginx # 2、下载镜像 docker pull nginx # 3、运行niginx镜像,映射宿主机的端口和容器的端口（宿主机端口:容器端口） docker run -d --name nginx01 -p 3344:80 nginx # 4、测试nginx是否启动成功 curl localhost:3344 # 5、进入容器查看配置文件 docker exec -it niginx01 /bin/bash # 6、查看niginx配置文件,查看nginx所在的路径 whereis nginx nginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx # 7、查看docker容器内存信息 docker stats 容器ID # 8、可以在启动容器时设置容器最小最大内存 -e 设置内存大小 四、容器数据卷 概念：容器之间可以有一个数据共享的技术，Docker容器中产生的数据同步到本地的过程，简单的说就是目录的挂载，将容器中的目录挂载到Linux上面。 4.1 数据卷使用 方式一：直接使用命令挂载 -v docker run -t -v 宿主机目录:容器目录 镜像 /bin/bash # 测试 docker run -it -v /home/test:/home centos /bin/bash 方式二：dockerfile方式进行挂载 4.2 匿名挂载和具名挂载 # 匿名挂载 -v 容器内路径 docker run -d -p --name nginx01 -v /ect/nginx nginx # 查看所有的volume情况 docker volume ls # 匿名挂载就是在-v时只写了容器内路径，没有写容器外路径 # 具名挂载 # -v 卷名:容器路径 docker run -d -p --name nginx01 -v juming-nginx:/ect/nginx nginx # 查看挂载路径 docker volume inspect juming-nginx ​ 总结：所有docker容器内的卷，没有指定目录的情况下都在/var/lib/docker/volums/xxxx/_data,通过具名挂载可以方便找到一个卷，大多数情况下使用具名挂载。 # 如何确定是具名挂载、匿名挂载、指定路径挂载 -v 容器内路径 -v 卷名:容器内路径 -v 宿主机路径:容器内路径 4.3 数据卷容器 ​ 命令：--volumes-from 五、DockerFile介绍 ​ 概念：dockerfile用来构建docker镜像的文件，命令脚本参数。 5.1 构建步骤 ​ 1、编写dockerfile文件，使用官方提供的默认文件名(DockerFile) ​ 2、docker build 构建一个镜像 ​ 3、docker run 镜像 ​ 4、docker push发布镜像 5.2 DockerFile构建过程 ​ DcokerFile：构建文件，定义一切步骤，源代码 ​ DockerImages：通过DockerFile构建生成镜像，最终发布和运行产品 ​ Docker容器：容器就是镜像运行起来提供服务器 5.3 DockerFile指令 FROM # 基础镜像，一切从这里开始构建 MAINTAINER # 镜像是谁写的，姓名+邮箱 RUN # 镜像运行是需要的命令 ADD # 添加其他程序（压缩包） WORKDIR # 镜像的工作目录 /bin/bash VOLUME # 挂载的目录位置 EXPOSE # 暴露端口 RUN # 运行命令 CMD # 指定容器启动后输出的命令,只有最后一个会生效，可被替代 ENTRYPOINT # 指定容器启动后输出的命令,可以追加命令 ONBUILD # 当构建一个被继承DockerFile这个时候会运行ONBUILD指令 COPY # 类似ADD命令，将文件拷贝到镜像中 ENV # 构建的时候设置环境变量 练习：创建自己的centos 在dockerhub中大部分的镜像都是从scratch开始构建，scratch作为基础构建 # 1、创建DockerFile文件 FROM centos MAINTAINER zchuanfa ENV MYPATH /usr/local WORKDIR $MYPATH # 设置进入容器后直接进入设置的目录 RUN yum -y install vim EXPOSE 80 CMD echo $MYPATH CMD /bin/bash # 2、build镜像 docker build -f myDockerFile -t myDocker:1.0 可以通过docker history 容器ID查看容器的构建过程 六、Docker网络 查看docker容器的ip信息 docker容器间的网络图 docker中所有的容器不指定网络的情况，都是docker0路由的，docker会给容器分配一个默认的ip。 6.2 容器互联--link # 通过--link设置通气直接互联 docker run -d P --name tomcat01 --link tomcat02 tomcat # 查看容器是否能ping得通 docker exec -it tomcat01 ping tomcat02 # --link只能单向连接，如果容器要互联需要同时设置--link 6.3 自定义网络 1、查看docker网络信息 docker network ls 2、自定义网络 # 自己创建网络 docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet # 容器配置自己定义的网络 docker run -d -P --net mynet tomcat 结论：自定义的网络已经帮我们维护好了对应的关系，平时使用自定义的方式来使用网络。 6.4 网络连通 通过connect方法将容器连通到网络中 # 将tomcat01连接到mynet网络 docker network connect mynet tomcat01 Copyright © zcf.com 2021 all right reserved，powered by Gitbook该页面最后修改于： 2021-06-02 10:04:22 "}}